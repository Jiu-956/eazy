# 后端学习指南 - 时序数据预测系统

## 1. 技术栈分析

### 1.1 核心技术
- **FastAPI**: 现代、快速的Python Web框架
- **SQLAlchemy**: Python SQL工具包和对象关系映射(ORM)
- **InfluxDB**: 时序数据库，专为时间序列数据优化
- **PostgreSQL/MySQL**: 关系数据库，存储用户、模型等元数据
- **Docker**: 容器化部署
- **TFB**: 时间序列预测框架

### 1.2 架构设计
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   前端 (Vue)    │◄──►│   后端 (FastAPI) │◄──►│   数据库层      │
│                 │    │                 │    │                 │
│ - 用户界面      │    │ - REST API      │    │ - PostgreSQL    │
│ - 数据可视化    │    │ - 业务逻辑      │    │ - InfluxDB      │
│ - 状态管理      │    │ - 数据处理      │    │ - Redis (缓存)  │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## 2. 数据库设计

### 2.1 关系数据库表结构 (PostgreSQL)

#### 用户表 (users)
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(20) DEFAULT 'user',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 数据集表 (datasets)
```sql
CREATE TABLE datasets (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    file_path VARCHAR(500) NOT NULL,
    file_size BIGINT NOT NULL,
    record_count INTEGER,
    status VARCHAR(20) DEFAULT 'uploading',
    format VARCHAR(20) NOT NULL, -- csv, json, xlsx, tfb
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 模型表 (models)
```sql
CREATE TABLE models (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    type VARCHAR(50) NOT NULL, -- lstm, gru, transformer
    description TEXT,
    status VARCHAR(20) DEFAULT 'training', -- training, ready, error
    accuracy FLOAT,
    parameters JSONB,
    metrics JSONB,
    model_path VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 预测任务表 (prediction_tasks)
```sql
CREATE TABLE prediction_tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    dataset_id UUID REFERENCES datasets(id) ON DELETE CASCADE,
    model_id UUID REFERENCES models(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending', -- pending, running, completed, failed
    parameters JSONB,
    progress INTEGER DEFAULT 0,
    result_path VARCHAR(500),
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP
);
```

#### 预测结果表 (prediction_results)
```sql
CREATE TABLE prediction_results (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_id UUID REFERENCES prediction_tasks(id) ON DELETE CASCADE,
    predictions JSONB NOT NULL,
    metrics JSONB,
    visualization_data JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 2.2 时序数据库设计 (InfluxDB)

#### 时序数据表结构
```sql
-- 原始时序数据
CREATE MEASUREMENT time_series_data (
    time TIMESTAMP,
    dataset_id TAG,
    value FLOAT,
    confidence FLOAT,
    upper_bound FLOAT,
    lower_bound FLOAT
);

-- 预测结果数据
CREATE MEASUREMENT prediction_data (
    time TIMESTAMP,
    task_id TAG,
    dataset_id TAG,
    model_id TAG,
    predicted_value FLOAT,
    actual_value FLOAT,
    confidence FLOAT
);
```

## 3. FastAPI 项目结构

### 3.1 目录结构
```
backend/
├── app/
│   ├── __init__.py
│   ├── main.py                 # FastAPI应用入口
│   ├── config.py              # 配置文件
│   ├── database.py            # 数据库连接
│   ├── models/                # SQLAlchemy模型
│   │   ├── __init__.py
│   │   ├── user.py
│   │   ├── dataset.py
│   │   ├── model.py
│   │   └── prediction.py
│   ├── schemas/               # Pydantic模型
│   │   ├── __init__.py
│   │   ├── user.py
│   │   ├── dataset.py
│   │   ├── model.py
│   │   └── prediction.py
│   ├── api/                   # API路由
│   │   ├── __init__.py
│   │   ├── auth.py
│   │   ├── datasets.py
│   │   ├── models.py
│   │   └── predictions.py
│   ├── services/              # 业务逻辑
│   │   ├── __init__.py
│   │   ├── auth_service.py
│   │   ├── dataset_service.py
│   │   ├── model_service.py
│   │   └── prediction_service.py
│   ├── utils/                 # 工具函数
│   │   ├── __init__.py
│   │   ├── auth.py
│   │   ├── file_handler.py
│   │   └── data_converter.py
│   └── core/                  # 核心功能
│       ├── __init__.py
│       ├── security.py
│       └── config.py
├── requirements.txt
├── Dockerfile
└── docker-compose.yml
```

### 3.2 核心代码示例

#### 主应用文件 (main.py)
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.api import auth, datasets, models, predictions
from app.database import engine, Base

# 创建数据库表
Base.metadata.create_all(bind=engine)

app = FastAPI(
    title="时序数据预测系统",
    description="基于机器学习的时序数据预测API",
    version="1.0.0"
)

# CORS中间件
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # 前端地址
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 注册路由
app.include_router(auth.router, prefix="/api/v1/auth", tags=["认证"])
app.include_router(datasets.router, prefix="/api/v1/datasets", tags=["数据集"])
app.include_router(models.router, prefix="/api/v1/models", tags=["模型"])
app.include_router(predictions.router, prefix="/api/v1/predictions", tags=["预测"])

@app.get("/")
async def root():
    return {"message": "时序数据预测系统API"}
```

#### 数据集服务 (dataset_service.py)
```python
from sqlalchemy.orm import Session
from app.models.dataset import Dataset
from app.schemas.dataset import DatasetCreate, DatasetUpdate
from app.utils.file_handler import FileHandler
from app.utils.data_converter import DataConverter
import uuid
import os

class DatasetService:
    def __init__(self, db: Session):
        self.db = db
        self.file_handler = FileHandler()
        self.data_converter = DataConverter()
    
    def create_dataset(self, dataset_data: DatasetCreate, user_id: str):
        # 保存上传的文件
        file_path = self.file_handler.save_uploaded_file(
            dataset_data.file, 
            dataset_data.name
        )
        
        # 创建数据集记录
        dataset = Dataset(
            id=str(uuid.uuid4()),
            user_id=user_id,
            name=dataset_data.name,
            description=dataset_data.description,
            file_path=file_path,
            file_size=dataset_data.file.size,
            format=dataset_data.format,
            status="uploading"
        )
        
        self.db.add(dataset)
        self.db.commit()
        self.db.refresh(dataset)
        
        # 异步处理文件
        self._process_dataset_async(dataset.id)
        
        return dataset
    
    def convert_dataset_format(self, dataset_id: str, target_format: str):
        dataset = self.db.query(Dataset).filter(Dataset.id == dataset_id).first()
        if not dataset:
            raise ValueError("数据集不存在")
        
        # 转换数据格式
        converted_data = self.data_converter.convert(
            dataset.file_path,
            dataset.format,
            target_format
        )
        
        # 保存转换后的数据
        converted_path = self.file_handler.save_converted_file(
            converted_data,
            f"{dataset.name}_converted.{target_format}"
        )
        
        return {
            "converted_path": converted_path,
            "format": target_format
        }
    
    def _process_dataset_async(self, dataset_id: str):
        # 异步处理数据集
        # 1. 验证数据格式
        # 2. 计算记录数量
        # 3. 提取元数据
        # 4. 更新状态
        pass
```

## 4. TFB框架学习

### 4.1 TFB简介
TFB (Time Series Forecasting Benchmark) 是一个专门用于时间序列预测的框架，支持多种深度学习模型。

### 4.2 核心功能
- **数据预处理**: 自动处理缺失值、异常值
- **特征工程**: 自动生成时间特征、滞后特征
- **模型训练**: 支持LSTM、GRU、Transformer等模型
- **模型评估**: 提供多种评估指标
- **预测服务**: 支持批量预测和实时预测

### 4.3 使用示例
```python
import tfb
import pandas as pd
import numpy as np

# 1. 数据准备
data = pd.read_csv('time_series_data.csv')
data['timestamp'] = pd.to_datetime(data['timestamp'])

# 2. 创建TFB数据集
dataset = tfb.Dataset(
    data=data,
    time_column='timestamp',
    value_columns=['value'],
    train_ratio=0.8,
    val_ratio=0.1,
    test_ratio=0.1
)

# 3. 配置模型
model_config = tfb.ModelConfig(
    model_type='lstm',
    input_length=100,
    output_length=10,
    hidden_size=128,
    num_layers=2,
    dropout=0.2
)

# 4. 训练模型
model = tfb.Model(config=model_config)
model.fit(dataset.train_data, dataset.train_labels)

# 5. 评估模型
metrics = model.evaluate(dataset.test_data, dataset.test_labels)
print(f"RMSE: {metrics['rmse']:.4f}")
print(f"MAE: {metrics['mae']:.4f}")

# 6. 进行预测
predictions = model.predict(dataset.test_data)
```

### 4.4 自定义模型
```python
import torch
import torch.nn as nn
import tfb

class CustomLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=2):
        super(CustomLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        # 取最后一个时间步的输出
        last_output = lstm_out[:, -1, :]
        output = self.fc(self.dropout(last_output))
        return output

# 注册自定义模型
tfb.register_model('custom_lstm', CustomLSTM)

# 使用自定义模型
model_config = tfb.ModelConfig(
    model_type='custom_lstm',
    input_length=100,
    output_length=10,
    hidden_size=128,
    num_layers=2
)
```

## 5. Docker部署

### 5.1 Dockerfile
```dockerfile
FROM python:3.9-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 5.2 docker-compose.yml
```yaml
version: '3.8'

services:
  # 后端API服务
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/timeseries_db
      - INFLUXDB_URL=http://influxdb:8086
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - influxdb
      - redis
    volumes:
      - ./data:/app/data

  # PostgreSQL数据库
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_DB=timeseries_db
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  # InfluxDB时序数据库
  influxdb:
    image: influxdb:2.0
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=password
      - DOCKER_INFLUXDB_INIT_ORG=timeseries
      - DOCKER_INFLUXDB_INIT_BUCKET=timeseries_data
    volumes:
      - influxdb_data:/var/lib/influxdb2
    ports:
      - "8086:8086"

  # Redis缓存
  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  influxdb_data:
  redis_data:
```

## 6. 学习资源

### 6.1 官方文档
- [FastAPI官方文档](https://fastapi.tiangolo.com/)
- [SQLAlchemy官方文档](https://docs.sqlalchemy.org/)
- [InfluxDB官方文档](https://docs.influxdata.com/)
- [TFB框架文档](https://github.com/tfb-framework/tfb)

### 6.2 实践建议
1. 先熟悉FastAPI基础，再学习高级特性
2. 掌握SQLAlchemy ORM的使用方法
3. 了解时序数据库的特点和优势
4. 学习TFB框架的核心概念和使用方法
5. 实践Docker容器化部署

### 6.3 开发流程
1. 设计数据库表结构
2. 创建SQLAlchemy模型
3. 定义Pydantic模式
4. 实现API路由
5. 编写业务逻辑服务
6. 集成TFB预测功能
7. 测试和优化
8. Docker化部署
